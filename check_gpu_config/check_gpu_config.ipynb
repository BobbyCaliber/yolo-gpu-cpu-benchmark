{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d5663fc-2eb7-4d0d-b6dd-b2e44faf231f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import pandas as pd\n",
    "\n",
    "# Инициализация CUDA\n",
    "cuda.init()\n",
    "\n",
    "# Получение информации о текущем GPU\n",
    "device = cuda.Device(0)  # Используем первый GPU\n",
    "name = device.name()\n",
    "num_cores = device.get_attribute(cuda.device_attribute.MULTIPROCESSOR_COUNT)  # Количество SM\n",
    "clock_rate = device.get_attribute(cuda.device_attribute.CLOCK_RATE)  # Частота в кГц\n",
    "clock_rate_ghz = clock_rate / 1e6  # Преобразуем в ГГц\n",
    "\n",
    "# Определяем архитектуру и параметры для расчета FLOPS\n",
    "compute_capability = device.compute_capability()\n",
    "if compute_capability >= (8, 0):  # Ampere (RTX 30xx, A100, H100)\n",
    "    if \"A100\" in name:  # Специализированные GPU для обучения                                                                  \n",
    "        tensor_cores_per_sm = 4 # tensor cores\n",
    "        cores_per_sm = 192\n",
    "        \n",
    "        fp64_ratio = 1 / 2\n",
    "        fp16_ratio = 4\n",
    "        fp64_tensor_ratio = 1\n",
    "        tf_32_ratio = 8\n",
    "        bf_16_ratio = 16\n",
    "             \n",
    "    elif \"H100\" in name: # Специализированные GPU для обучения  # !!!! для h100 вообще cores per sm 256\n",
    "        tensor_cores_per_sm = 4 # tensor cores\n",
    "        cores_per_sm = 256\n",
    "\n",
    "        fp64_ratio = 1 / 2\n",
    "        fp16_ratio = 4\n",
    "        fp64_tensor_ratio = 0\n",
    "        tf_32_ratio = 0\n",
    "        bf_16_ratio = 0\n",
    "        \n",
    "    else:  # Обычные Ampere GPU (RTX 30xx) и 40xx\n",
    "        tensor_cores_per_sm = 4 # tensor cores\n",
    "        cores_per_sm = 128\n",
    "\n",
    "        fp64_ratio = 1 / 64\n",
    "        fp16_ratio = 1\n",
    "        fp64_tensor_ratio = 0\n",
    "        tf_32_ratio = 0\n",
    "        bf_16_ratio = 0        \n",
    "          \n",
    "elif compute_capability == (7, 5):  # Turing (RTX 20xx, Quadro RTX)\n",
    "    if \"GTX 16\" in name:  # GTX 16xx без Tensor Cores\n",
    "        tensor_cores_per_sm = 0\n",
    "        cores_per_sm = 64\n",
    "\n",
    "        fp64_ratio = 1 / 32\n",
    "        fp16_ratio = 2\n",
    "        fp64_tensor_ratio = 0\n",
    "        tf_32_ratio = 0\n",
    "        bf_16_ratio = 0\n",
    "             \n",
    "    else:  # RTX 20xx и Quadro RTX                                            #!!! чекнуть про 20 серию и из тюринга про fp\n",
    "        tensor_cores_per_sm = 8                                  # тут сверяться с gpu database насчет fp ratio остальные fp расчитываются засчет дроби и fp32\n",
    "        cores_per_sm = 64\n",
    "        \n",
    "        fp64_ratio = 1 / 32\n",
    "        fp16_ratio = 2\n",
    "        fp64_tensor_ratio = 0\n",
    "        tf_32_ratio = 0\n",
    "        bf_16_ratio = 0\n",
    "        \n",
    "elif compute_capability == (7, 0):  # Volta (Tesla V100)\n",
    "    tensor_cores_per_sm = 8\n",
    "    cores_per_sm = 128\n",
    "\n",
    "    fp64_ratio = 1 / 2\n",
    "    fp16_ratio = 2\n",
    "    fp64_tensor_ratio = 0\n",
    "    tf_32_ratio = 0\n",
    "    bf_16_ratio = 0\n",
    " \n",
    "else:\n",
    "    tensor_cores_per_sm = 0\n",
    "    cores_per_sm = 64\n",
    "    \n",
    "    fp64_ratio = 1 / 32\n",
    "    fp16_ratio = 0\n",
    "    fp64_tensor_ratio = 0\n",
    "    tf_32_ratio = 0\n",
    "    bf_16_ratio = 0\n",
    "    \n",
    "# Подсчет общего количества CUDA-ядер\n",
    "total_cores = num_cores * cores_per_sm\n",
    "# Подсчет общего количества тензор-ядер\n",
    "num_tensor_cores = num_cores * tensor_cores_per_sm\n",
    "\n",
    "# FP32 FLOPS\n",
    "fp32_flops = total_cores * 2 * clock_rate_ghz / 1000 # для терафлопс                   # это основные flops это тут база\n",
    "fp64_flops = fp32_flops * fp64_ratio\n",
    "fp16_flops = fp32_flops * fp16_ratio\n",
    "fp64_tensor_flops = fp64_flops * fp64_tensor_ratio\n",
    "tf32_flops = fp64_flops * tf_32_ratio\n",
    "bf16_flops = fp32_flops * bf_16_ratio\n",
    "\n",
    "dict = {}\n",
    "dict['GPU Name'] = name\n",
    "dict['Compute Capability (cuda version)'] = f'{compute_capability}'\n",
    "\n",
    "dict['Number of SMs'] = num_cores\n",
    "dict['Cores per SM'] = cores_per_sm\n",
    "dict['Total CUDA Cores'] = total_cores\n",
    "dict['Number of Tensor Cores'] = num_tensor_cores\n",
    "\n",
    "dict['Clock Rate (GHz) boost'] = clock_rate_ghz\n",
    "\n",
    "dict['FP32 FLOPS (TFLOPS)'] = fp32_flops\n",
    "dict['TF32 FLOPS (TFLOPS)'] = tf32_flops\n",
    "\n",
    "dict['FP16 FLOPS (TFLOPS)'] = fp16_flops\n",
    "dict['BF16 FLOPS (TFLOPS)'] = bf16_flops\n",
    "\n",
    "dict['FP64 FLOPS (GFLOPS)'] = fp64_flops * 1000\n",
    "dict['FP64 TENSOR FLOPS (TFLOPS)'] = fp64_tensor_flops\n",
    "\n",
    "# Вывод результатов\n",
    "result = pd.DataFrame(dict, index=[0])\n",
    "result.to_csv('gpu_config.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}